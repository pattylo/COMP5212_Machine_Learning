{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP to train CIFAR-10 Multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as td\n",
    "import random, time\n",
    "import torchvision\n",
    "\n",
    "print('lib import succeed')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cifar_loaders(batch_size, shuffle_test=False): \n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.225, 0.225, 0.225])\n",
    "    train = datasets.CIFAR10('./', train=True, download=True, \n",
    "        transform=transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, 4),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    test = datasets.CIFAR10('./', train=False, \n",
    "        transform=transforms.Compose([transforms.ToTensor(), normalize]))\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size,\n",
    "        shuffle=True, pin_memory=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size,\n",
    "        shuffle=shuffle_test, pin_memory=True)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "batch_size = 64\n",
    "test_batch_size = 64\n",
    "\n",
    "train_loader, _ = cifar_loaders(batch_size)\n",
    "_, test_loader = cifar_loaders(test_batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check what we downloaded:\n",
    "\n",
    "CIFAR-10 contains 50000 training images and 10000 training images\n",
    "\n",
    "50000/batch size = len(train_loader) \n",
    "\n",
    "10000/batch size = len(test_loader)\n",
    "\n",
    "per image: 32x32 with 3 channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'training dataset size: {len(train_loader)}')\n",
    "\n",
    "i = 0;\n",
    "for what in train_loader:\n",
    "    for image in what[0]:\n",
    "        print(len(image))\n",
    "    for class_id in what[1]:\n",
    "        print(class_id)\n",
    "    \n",
    "    # print(whaxt)\n",
    "    i = i + 1\n",
    "    if(i > 0):\n",
    "        break;\n",
    "\n",
    "# print(f'per image size: {len(train_loader[0])}')\n",
    "print(f'testing dataset size: {len(test_loader)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "layer_no = 7\n",
    "w_relu = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define neural network here - MLP (fully connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(MLP, self).__init__() \n",
    "\n",
    "        self.lay_no = layer_no\n",
    "        self.input_size = 3 * 32 * 32\n",
    "        self.output_size = 10\n",
    "        self.per_layer_diff = round(3 * 32 * 32 / layer_no, 0)\n",
    "        \n",
    "        self.fc_layers = nn.ModuleList()\n",
    "\n",
    "        print(self.per_layer_diff)\n",
    "        print(self.input_size - (1-1) * self.per_layer_diff)\n",
    "        print(self.input_size - 1 * self.per_layer_diff)\n",
    "\n",
    "        # Corrected dimensions for fcl1 and fcl2\n",
    "        for i in range(self.lay_no):\n",
    "            in_dim = int(self.input_size - (i + 1 -1) * self.per_layer_diff)\n",
    "            out_dim = int(self.input_size - (i+1) * self.per_layer_diff) if i < layer_no - 1 else self.output_size\n",
    "\n",
    "            layer = nn.Linear(in_dim, out_dim, bias=True)\n",
    "            self.fc_layers.append(layer)\n",
    "            \n",
    "        for what in self.fc_layers:\n",
    "            print(what)\n",
    "            \n",
    "        print(\"MLP INITIALIZED!\")\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        \n",
    "        for layer in self.fc_layers:\n",
    "            x = layer(x)\n",
    "            if w_relu:\n",
    "                x = F.relu(x)  # Applying ReLU activation after each layer\n",
    "\n",
    "        return x\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "net = MLP()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more predefinition before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_no = 20\n",
    "classnames = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "print(net.fc_layers)\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defind loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4) # weight_decay for regularization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "begin_time = time.time()\n",
    "logname = 'result_MLP.txt'\n",
    "\n",
    "if os.path.exists(logname):\n",
    "    os.remove(logname)\n",
    "f = open(logname, 'w')\n",
    "f.write('Run Start Time: ' + str(time.ctime()))\n",
    "f.write('Learning Rate\\t%f\\n' % learning_rate)\n",
    "\n",
    "for epoch in range(epoch_no):\n",
    "    epoch_start_time = time.time()\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    # train\n",
    "    for i, data in enumerate(train_loader):\n",
    "        \n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net.forward(images)\n",
    "        batch_loss = loss_func(outputs, labels)\n",
    "        \n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += batch_loss.item()\n",
    "        \n",
    "    f.write(\"Epoch\\t%d\\tLoss\\t%f\\t\" % (epoch + 1, epoch_loss / (i + 1)))\n",
    "    epoch_end_time = time.time()\n",
    "    \n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # test\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            \n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = net.forward(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct_matrix = (predicted == labels)\n",
    "\n",
    "            c = correct_matrix.squeeze()\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "            total += labels.size(0)\n",
    "            correct += correct_matrix.sum().item()\n",
    "            \n",
    "    f.write('Accuracy of the network [%d/%d]\\t%f %%\\n' % (correct, total, 100 * correct / total))\n",
    "    print(f'Epoch:{epoch} Complete!')\n",
    "\n",
    "f.write('Training Complete: ' + str(time.ctime()) + '\\n')\n",
    "run_time = time.time() - begin_time\n",
    "f.write('Runtime\\t%f\\n' % run_time)\n",
    "f.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "namehere = 'result_MLP'\n",
    "# Open the file and read its content\n",
    "with open(namehere+'.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Use regular expressions to find loss and accuracy values\n",
    "loss_pattern = re.compile(r'Epoch\\s*\\d+\\s*Loss\\s*([\\d.]+)')\n",
    "accuracy_pattern = re.compile(r'Accuracy of the network \\[([\\d]+)/\\d+\\]\\s*([\\d.]+)')\n",
    "\n",
    "# Find all occurrences of loss and accuracy in the content\n",
    "loss_values = [float(match.group(1)) for match in loss_pattern.finditer(content)]\n",
    "accuracy_values = [float(match.group(2)) for match in accuracy_pattern.finditer(content)]\n",
    "\n",
    "# Print the extracted values\n",
    "print(\"Loss values:\", loss_values)\n",
    "print(\"Accuracy values:\", accuracy_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filename = namehere + \".pdf\"\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [8.0,4.0]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "plt.title(namehere)\n",
    "\n",
    "x = list(range(1,21)) \n",
    "plt.plot(x,loss_values, '-bD',  c='blue', mfc='red', mec='k')\n",
    "plt.xticks(np.arange(min(x), max(x)+1, 1.0))\n",
    "plt.xlabel(\"epochs\", )\n",
    "plt.ylabel(\"Loss/No. of Batch\")\n",
    "plt.ylim(0.0,2.5)\n",
    "plt.savefig(\"./\" + filename, format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = namehere + \"_accuracy\" + \".pdf\"\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [8.0,4.0]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "plt.title(\"Accuracy @ \" + namehere)\n",
    "\n",
    "x = list(range(1,21))\n",
    "plt.plot(x, accuracy_values, '-bD',  c='blue', mfc='red', mec='k')\n",
    "plt.xticks(np.arange(min(x), max(x)+1, 1.0))\n",
    "plt.xlabel(\"epochs\", )\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.ylim(20, 90)\n",
    "plt.savefig(\"./\" + filename, format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
